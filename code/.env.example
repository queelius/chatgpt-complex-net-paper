# ChatGPT Complex Network Analysis Configuration
# Copy this file to .env and customize for your setup

# ============================================
# OLLAMA CONFIGURATION
# ============================================
# Ollama API endpoint for generating embeddings
# Change to localhost:11434 if running locally
OLLAMA_HOST=http://192.168.0.225:11434

# Embedding model to use
# Options: nomic-embed-text, mxbai-embed-large, all-minilm, etc.
MODEL_NAME=nomic-embed-text

# ============================================
# DATA PATHS
# ============================================
# Input directory containing raw ChatGPT conversation JSONs
INPUT_DIR=../dev/chatgpt-4-11-2025_json_no_embeddings

# Base output directory for ablation study results
OUTPUT_BASE_DIR=../dev/ablation_study

# ============================================
# ABLATION STUDY PARAMETERS
# ============================================
# Similarity threshold for edge filtering (0.0 to 1.0)
# Higher values = sparser networks with only strong connections
SIMILARITY_THRESHOLD=0.9

# Use GPU for edge generation (true/false)
USE_GPU=false

# Skip embedding generation if already exists (true/false)
SKIP_EMBEDDINGS=false

# ============================================
# PROCESSING PARAMETERS
# ============================================
# Chunk size for long messages (words)
CHUNK_SIZE=512

# Overlap between chunks (words)
CHUNK_OVERLAP=50

# Chunk aggregation method (mean or sum)
CHUNK_AGGREGATION=mean

# ============================================
# NETWORK ANALYSIS PARAMETERS
# ============================================
# Maximum nodes for exact shortest path calculation
# (sampling used for larger networks)
MAX_NODES_EXACT_PATH=1000

# Number of nodes to sample for approximate calculations
SAMPLE_SIZE=100

# Number of iterations for betweenness centrality approximation
BETWEENNESS_K=100

# ============================================
# LOGGING AND OUTPUT
# ============================================
# Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# Save intermediate files (true/false)
SAVE_INTERMEDIATE=true

# Output formats for network export
# Options: gexf, graphml, gml (comma-separated)
EXPORT_FORMATS=gexf

# ============================================
# WEIGHT RATIOS (for custom runs)
# ============================================
# Comma-separated list of user:ai weight ratios
# Format: "user1:ai1,user2:ai2,..."
# Default is the full ablation study set
CUSTOM_RATIOS=""

# ============================================
# PERFORMANCE TUNING
# ============================================
# Number of parallel workers for processing
# Set to -1 for auto (number of CPU cores)
NUM_WORKERS=-1

# Batch size for embedding generation
EMBEDDING_BATCH_SIZE=10

# Request timeout for Ollama API (seconds)
OLLAMA_TIMEOUT=120

# Maximum retries for failed API calls
MAX_RETRIES=3

# Delay between retries (seconds)
RETRY_DELAY=5